package benchmarks

import (
	"context"
	"encoding/json"
	"io"
	"testing"
	"time"

	"github.com/ajitpratap0/mcp-sdk-go/pkg/protocol"
	"github.com/ajitpratap0/mcp-sdk-go/pkg/transport"
)

// BenchmarkStdioTransport tests stdio transport performance
func BenchmarkStdioTransport(b *testing.B) {
	b.Run("SendRequest", func(b *testing.B) {
		benchmarkTransportSendRequest(b, createStdioTransport(b))
	})

	b.Run("SendNotification", func(b *testing.B) {
		benchmarkTransportSendNotification(b, createStdioTransport(b))
	})

	b.Run("BatchRequest/10", func(b *testing.B) {
		benchmarkTransportBatchRequest(b, createStdioTransport(b), 10)
	})

	b.Run("BatchRequest/100", func(b *testing.B) {
		benchmarkTransportBatchRequest(b, createStdioTransport(b), 100)
	})

	b.Run("BatchRequest/1000", func(b *testing.B) {
		benchmarkTransportBatchRequest(b, createStdioTransport(b), 1000)
	})
}

// BenchmarkStreamableHTTPTransport tests HTTP transport performance
func BenchmarkStreamableHTTPTransport(b *testing.B) {
	b.Run("SendRequest", func(b *testing.B) {
		benchmarkTransportSendRequest(b, createHTTPTransport(b))
	})

	b.Run("SendNotification", func(b *testing.B) {
		benchmarkTransportSendNotification(b, createHTTPTransport(b))
	})

	b.Run("BatchRequest/10", func(b *testing.B) {
		benchmarkTransportBatchRequest(b, createHTTPTransport(b), 10)
	})

	b.Run("BatchRequest/100", func(b *testing.B) {
		benchmarkTransportBatchRequest(b, createHTTPTransport(b), 100)
	})

	b.Run("ConcurrentRequests/10", func(b *testing.B) {
		benchmarkConcurrentRequests(b, createHTTPTransport(b), 10)
	})

	b.Run("ConcurrentRequests/100", func(b *testing.B) {
		benchmarkConcurrentRequests(b, createHTTPTransport(b), 100)
	})
}

// benchmarkTransportSendRequest benchmarks single request performance
func benchmarkTransportSendRequest(b *testing.B, t transport.Transport) {
	ctx := context.Background()

	// Set up echo handler
	t.RegisterRequestHandler("echo", func(ctx context.Context, params interface{}) (interface{}, error) {
		return params, nil
	})

	// Initialize transport
	if err := t.Initialize(ctx); err != nil {
		b.Fatal(err)
	}
	if err := t.Start(ctx); err != nil {
		b.Fatal(err)
	}
	defer t.Stop(ctx)

	// Prepare test data
	testData := map[string]interface{}{
		"message":   "Hello, MCP!",
		"timestamp": time.Now().Unix(),
		"data": map[string]interface{}{
			"field1": "value1",
			"field2": 42,
			"field3": true,
		},
	}

	b.ResetTimer()
	b.ReportAllocs()

	for i := 0; i < b.N; i++ {
		_, err := t.SendRequest(ctx, "echo", testData)
		if err != nil {
			b.Fatal(err)
		}
	}
}

// benchmarkTransportSendNotification benchmarks notification performance
func benchmarkTransportSendNotification(b *testing.B, t transport.Transport) {
	ctx := context.Background()

	// Set up notification handler
	notificationReceived := make(chan bool, b.N)
	t.RegisterNotificationHandler("notify", func(ctx context.Context, params interface{}) error {
		notificationReceived <- true
		return nil
	})

	// Initialize transport
	if err := t.Initialize(ctx); err != nil {
		b.Fatal(err)
	}
	if err := t.Start(ctx); err != nil {
		b.Fatal(err)
	}
	defer t.Stop(ctx)

	// Prepare test data
	testData := map[string]interface{}{
		"event":     "test_notification",
		"timestamp": time.Now().Unix(),
	}

	b.ResetTimer()
	b.ReportAllocs()

	for i := 0; i < b.N; i++ {
		err := t.SendNotification(ctx, "notify", testData)
		if err != nil {
			b.Fatal(err)
		}
	}

	// Wait for all notifications to be processed
	for i := 0; i < b.N; i++ {
		select {
		case <-notificationReceived:
		case <-time.After(5 * time.Second):
			b.Fatal("Timeout waiting for notification")
		}
	}
}

// benchmarkTransportBatchRequest benchmarks batch request performance
func benchmarkTransportBatchRequest(b *testing.B, t transport.Transport, batchSize int) {
	ctx := context.Background()

	// Set up echo handler
	t.RegisterRequestHandler("echo", func(ctx context.Context, params interface{}) (interface{}, error) {
		return params, nil
	})

	// Initialize transport
	if err := t.Initialize(ctx); err != nil {
		b.Fatal(err)
	}
	if err := t.Start(ctx); err != nil {
		b.Fatal(err)
	}
	defer t.Stop(ctx)

	// Prepare batch
	batch := &protocol.JSONRPCBatchRequest{}
	for i := 0; i < batchSize; i++ {
		req, _ := protocol.NewRequest(i, "echo", map[string]interface{}{
			"index": i,
			"data":  "test",
		})
		*batch = append(*batch, req)
	}

	b.ResetTimer()
	b.ReportAllocs()

	for i := 0; i < b.N; i++ {
		resp, err := t.SendBatchRequest(ctx, batch)
		if err != nil {
			b.Fatal(err)
		}
		if resp.Len() != batchSize {
			b.Fatalf("Expected %d responses, got %d", batchSize, resp.Len())
		}
	}
}

// benchmarkConcurrentRequests benchmarks concurrent request handling
func benchmarkConcurrentRequests(b *testing.B, t transport.Transport, concurrency int) {
	ctx := context.Background()

	// Set up echo handler
	t.RegisterRequestHandler("echo", func(ctx context.Context, params interface{}) (interface{}, error) {
		// Simulate some processing time
		time.Sleep(1 * time.Millisecond)
		return params, nil
	})

	// Initialize transport
	if err := t.Initialize(ctx); err != nil {
		b.Fatal(err)
	}
	if err := t.Start(ctx); err != nil {
		b.Fatal(err)
	}
	defer t.Stop(ctx)

	b.ResetTimer()
	b.ReportAllocs()

	// Run concurrent requests
	b.RunParallel(func(pb *testing.PB) {
		testData := map[string]interface{}{
			"message": "concurrent test",
		}

		for pb.Next() {
			_, err := t.SendRequest(ctx, "echo", testData)
			if err != nil {
				b.Fatal(err)
			}
		}
	})
}

// Helper functions to create transports

func createStdioTransport(b *testing.B) transport.Transport {
	// Create pipes for testing
	clientReader, serverWriter := io.Pipe()
	serverReader, clientWriter := io.Pipe()

	config := transport.DefaultTransportConfig(transport.TransportTypeStdio)
	config.StdioReader = clientReader
	config.StdioWriter = clientWriter

	t, err := transport.NewTransport(config)
	if err != nil {
		b.Fatal(err)
	}

	// Start echo server in background
	go func() {
		decoder := json.NewDecoder(serverReader)
		encoder := json.NewEncoder(serverWriter)

		for {
			var msg json.RawMessage
			if err := decoder.Decode(&msg); err != nil {
				return
			}

			// Parse message
			var base protocol.JSONRPCMessage
			if err := json.Unmarshal(msg, &base); err != nil {
				continue
			}

			// Handle based on type
			if base.Method != "" && base.ID != nil {
				// Request - send response
				var req protocol.Request
				json.Unmarshal(msg, &req)

				resp := &protocol.Response{
					JSONRPCMessage: protocol.JSONRPCMessage{
						JSONRPC: protocol.JSONRPCVersion,
					},
					ID:     req.ID,
					Result: req.Params,
				}
				encoder.Encode(resp)
			} else if base.Method != "" {
				// Notification - handle internally
				var notif protocol.Notification
				json.Unmarshal(msg, &notif)
				// Process notification
			} else if protocol.IsBatch(msg) {
				// Batch request
				var batch protocol.JSONRPCBatchRequest
				json.Unmarshal(msg, &batch)

				var responses protocol.JSONRPCBatchResponse
				for _, item := range batch {
					if req, ok := item.(*protocol.Request); ok {
						resp := &protocol.Response{
							JSONRPCMessage: protocol.JSONRPCMessage{
								JSONRPC: protocol.JSONRPCVersion,
							},
							ID:     req.ID,
							Result: req.Params,
						}
						responses = append(responses, resp)
					}
				}
				encoder.Encode(responses)
			}
		}
	}()

	return t
}

func createHTTPTransport(b *testing.B) transport.Transport {
	// For HTTP transport benchmarks, we'll use a mock setup
	// In real benchmarks, this would connect to an actual server
	config := transport.DefaultTransportConfig(transport.TransportTypeStreamableHTTP)
	config.Endpoint = "http://localhost:8080/mcp"

	// For benchmark purposes, create stdio transport as mock
	// Real implementation would use actual HTTP server
	return createStdioTransport(b)
}

// Memory allocation benchmarks

// BenchmarkMessageSerialization tests protocol message serialization performance
func BenchmarkMessageSerialization(b *testing.B) {
	b.Run("Request", func(b *testing.B) {
		req, _ := protocol.NewRequest("123", "test_method", map[string]interface{}{
			"key1": "value1",
			"key2": 42,
			"key3": true,
		})

		b.ResetTimer()
		b.ReportAllocs()

		for i := 0; i < b.N; i++ {
			_, err := json.Marshal(req)
			if err != nil {
				b.Fatal(err)
			}
		}
	})

	b.Run("Response", func(b *testing.B) {
		resp := &protocol.Response{
			JSONRPCMessage: protocol.JSONRPCMessage{
				JSONRPC: protocol.JSONRPCVersion,
			},
			ID:     "123",
			Result: json.RawMessage(`{"status":"success","data":{"field1":"value1","field2":42}}`),
		}

		b.ResetTimer()
		b.ReportAllocs()

		for i := 0; i < b.N; i++ {
			_, err := json.Marshal(resp)
			if err != nil {
				b.Fatal(err)
			}
		}
	})

	b.Run("BatchRequest/100", func(b *testing.B) {
		batch := &protocol.JSONRPCBatchRequest{}
		for i := 0; i < 100; i++ {
			req, _ := protocol.NewRequest(i, "method", map[string]interface{}{"index": i})
			*batch = append(*batch, req)
		}

		b.ResetTimer()
		b.ReportAllocs()

		for i := 0; i < b.N; i++ {
			_, err := json.Marshal(batch)
			if err != nil {
				b.Fatal(err)
			}
		}
	})
}

// BenchmarkMessageDeserialization tests protocol message deserialization performance
func BenchmarkMessageDeserialization(b *testing.B) {
	b.Run("Request", func(b *testing.B) {
		data := []byte(`{"jsonrpc":"2.0","id":"123","method":"test_method","params":{"key1":"value1","key2":42,"key3":true}}`)

		b.ResetTimer()
		b.ReportAllocs()

		for i := 0; i < b.N; i++ {
			var req protocol.Request
			err := json.Unmarshal(data, &req)
			if err != nil {
				b.Fatal(err)
			}
		}
	})

	b.Run("Response", func(b *testing.B) {
		data := []byte(`{"jsonrpc":"2.0","id":"123","result":{"status":"success","data":{"field1":"value1","field2":42}}}`)

		b.ResetTimer()
		b.ReportAllocs()

		for i := 0; i < b.N; i++ {
			var resp protocol.Response
			err := json.Unmarshal(data, &resp)
			if err != nil {
				b.Fatal(err)
			}
		}
	})
}
